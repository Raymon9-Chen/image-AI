{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5VBZ4PIMrBp",
        "outputId": "2364d8f6-2a64-4199-af90-d5bebc9592a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import argmax\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Helper functions\n",
        "def show_min_max(array, i):\n",
        "  random_image = array[i]\n",
        "  print(\"min and max value in image: \", random_image.min(), random_image.max())\n",
        "\n",
        "\n",
        "def plot_image(array, i, labels):\n",
        "  plt.imshow(np.squeeze(array[i]))\n",
        "  plt.title(str(label_names[argmax(labels[i])]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "\n",
        "# Add variables to keep track of image size\n",
        "image_width = 32\n",
        "image_height = 32\n",
        "# Add a variable for amount of output classes\n",
        "num_classes = 10\n",
        "# Add a variable to keep track of input shape.\n",
        "input_shape = (32, 32, 3)\n",
        "# Load data in. The dataset is called cifar10.\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "# Load a backup copy of the data.\n",
        "train_images_backup, train_labels_backup, test_images_backup, test_labels_backup = train_images, train_labels, test_images, test_labels\n",
        "# Set up array for labels:\n",
        "label_names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Code to adjust the label arrays.\n",
        "train_labels_backup = [item for sublist in train_labels_backup for item in sublist]\n",
        "test_labels_backup = [item for sublist in test_labels_backup for item in sublist]\n",
        "\n",
        "# Print the shape of the data to make sure it loaded in correctly\n",
        "#print(train_images.shape)\n",
        "# Use plot_image and show_min_max to see the 100th image before you normalize it.\n",
        "\n",
        "# Convert test and train images to float32\n",
        "train_images = train_images.astype(\"float32\")\n",
        "test_images = test_images.astype(\"float32\")\n",
        "# Divide images by 255 to keep them betweek 0 and 1\n",
        "train_images = train_images/255\n",
        "test_images = test_images/255\n",
        "# Convert labels using one-hot encoding.\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "# Use plot_image and show_min_max to make sure the data has been loaded correctly.\n",
        "#plot_image(train_images, 100, train_labels)\n",
        "#show_min_max(train_images, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD1IXEYVhXI-",
        "outputId": "8833a7f9-17b0-4298-f9a1-6d71589096d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 128)       3584      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 14, 14, 64)        256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 12, 12, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 64)          73792     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 8, 8, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               524416    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 788426 (3.01 MB)\n",
            "Trainable params: 788042 (3.01 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 23s 18ms/step - loss: 1.6057 - accuracy: 0.4339 - val_loss: 1.3033 - val_accuracy: 0.5389\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 14s 17ms/step - loss: 1.1386 - accuracy: 0.5972 - val_loss: 1.1213 - val_accuracy: 0.6104\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.9486 - accuracy: 0.6634 - val_loss: 1.1723 - val_accuracy: 0.6043\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.8228 - accuracy: 0.7100 - val_loss: 0.9678 - val_accuracy: 0.6648\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.7413 - accuracy: 0.7383 - val_loss: 0.7934 - val_accuracy: 0.7245\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.6800 - accuracy: 0.7587 - val_loss: 0.7233 - val_accuracy: 0.7457\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.6353 - accuracy: 0.7749 - val_loss: 0.7668 - val_accuracy: 0.7303\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5832 - accuracy: 0.7926 - val_loss: 0.6972 - val_accuracy: 0.7672\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.5459 - accuracy: 0.8075 - val_loss: 0.7266 - val_accuracy: 0.7542\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.5112 - accuracy: 0.8169 - val_loss: 0.6983 - val_accuracy: 0.7667\n",
            "Test accuracy: 0.766700029373169\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "epochs = 10 # The amount of batches of data being sent at once\n",
        "batch_size = 64\n",
        "model = Sequential() # Creates a Sequential Layer\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', input_shape=input_shape))  # Adds a Convolutional Layer\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=input_shape)) # Adds another Convolutional Layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # Pooling Layer\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(1,1)))\n",
        "model.add(Dropout(rate=0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3),activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1,1)))\n",
        "model.add(Dropout(rate=0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 128, activation = 'relu'))\n",
        "model.add(Dense(units = num_classes, activation = 'softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_data=(test_images, test_labels), shuffle=True)\n",
        "scores = model.evaluate(test_images, test_labels,verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZRyHVIJx-fi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}